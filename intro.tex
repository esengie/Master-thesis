\section*{Введение}
  Теории зависимых типов были впервые подробно рассмотрены Мартин-Лёфом в 1980 году в курсе лекций, прочтенных им в Падове, которые были расширены в книгу~\cite{martin_lof}. Одна из основных его мотиваций заключалась в том, чтобы предложить альтернативу теории множеств для формализации математики. Основным преимуществом теории типов является ... 

Это называется соответствием Карри-Говарда-Ламбека\cite{curry_how} --- когда типы языка соответствуют утверждениям в соответствующей логике, а выражения этих типов доказательствами соответствующих утверждений. Достоинство данного подхода заключается в том, что проверка доказательств перекладывается на алгоритм проверки типов соответсвующего языка программирования, а это автоматизированный процесc.

Наиболее известными примерами языков, которые пользуются соответствием Карри-Говарда для доказательства математических утверждений являются Coq\cite{coq} и Agda\cite{agda}. Например, доказательство теоремы о четырех красках было завершено в 2005 году с помощью Coq\cite{weisstein2002four}.

Другая область применения теории типов --- это верификация программ. Так как использование произвольных выражений языка на уровне типов значительно расширяет экспрессивность системы типов языка, можно задавать произвольные ограничения на входные и выходные данные функций языка. Таким способом можно описывать и формально верифицировать даже большие системы, например существует формально верифицированная версия Standard ML\cite{ml_lang} под названием CakeML\cite{ml_cake}. Пример относительно простого доказательства --- корректности функции filter на Agda приведен в Приложении~\ref{sort_proof}.

\hfill

При реализации языков с зависимыми типами возникает ряд типичных задач, основной из которых является реализация функции проверки типов. Однако для eё реализации необходимо реализовывать функцию вычисления выражений и проверки их на равенство, для этого необходимо уметь совершать манипуляции с выражениями языка --- а значит их тоже реализовывать. Основными манипуляциями являются работа со связываниями: абстракция по переменной и подстановка выражения вместо переменной (подробнее про реализацию в подразделе\ref{impl_intro}). Цель данной работы заключается в том, чтобы реализовать приложение, которое по спецификации зависимого языка (подробнее о языке спицификации в Разделе~\ref{lang_spec}) генерирует исходный код на каком-либо языке (для этих целей мы используем Haskell\cite{haskell}), осуществляющий проверку типов заданного языка.

С одной стороны такое приложение упростит реализацию языков с зависимыми типами, так как, благодаря ему, можно будет избежать реализации фактически шаблонного кода. С другой стороны, позволит эксперементировать с различными вариациями теорий типов.

Поэтому основной задачей данной работы является определение языка спецификации зависимых языков, с дальнейшей генерацией представления АСД этого языка и функций работы с деревом в виде модуля Haskell\cite{haskell}. \textit{АСД} --- абстрактное синтаксическое дерево, по любому выражению языка можно составить дерево, узлами этого дерева будут конструкции языка, а потомками узла выражения к которым конструкция применяется. Генерируемый модуль содержит функции проверки типов, вычисления выражений, работы с контекстами и стандартных операций над выражениями (такие как подстановка, абстракция и проверка на равенство).

Текст работы состоит из трёх основных разделов. Каждый из них мы обсудим подробнее в соответствующем подразделе введения.

\subsection*{Языки с зависимыми типами}

Все зависимые языки состоят из некоторых конструкций языка, с помощью которых пишутся все выражения в языке.

Например, язык булевых выражений Bool состоит из четырёх конструкций: тип Bool, константы true и false, и конструкция if-then-else. Нас интересуют только типизированные языки, поэтому для каждой конструкции должны быть прописаны правила типизации. В нашем языке true имеет тип Bool, false имеет тип Bool, if-then-else принимает четыре аргумента --- выражение типа Bool, тип возвращаемого выражения и два выражения, имеющих тип равный возвращаемому. Формально языки задаются через правила вывода(см. Раздел~\ref{lang_spec}).

Также необходимо задавать правила вычисления языка, их принято называть правилами редукции языка. Для Bool их всего два, а именно для конструкции if-then-else мы возвращаем либо ветку then, либо ветку else в зависимости от первого её аргумента.

Выше был представлен пример обычного, независимого языка Bool. Чтобы из него сделать зависимый язык Bool, нужно модифицировать конструкцию if-then-else. Теперь вторым её аргументом будет функция, возвращающая тип возвращаемого выражения в зависимости от переданного ей аргумента типа Bool. Тогда станет возможной конструкция вида: if-then-else(t, f, True, 1), которая будет возвращать либо True типа Bool, либо 1 типа Int в зависимости от истинности первого аргумента конструкции. Более подробное введение в зависимые языки можно найти в~\cite{martin_lof}.

\subsection*{Определение языка спецификаций}

Наша цель научиться записывать правила типизации формально и по такому описанию генерировать код, который бы осуществлял проверку типов для соответствующего языка.

Формализация языка происходит путем описания его спецификации. В спецификации задаются возможные уровни выражений языка, например в Haskell это типы, термы и виды. Затем описываются его конструкции --- описываются уровни аргументов и возвращаемого выражения. Также описываются правила типизации каждой конструкции и правила редукции языка. Правила типизации и редукции содержат переменные языка спецификации, которые мы впредь называем \textit{метапеременными}, так как они являются переменными нашего мета-языка --- языка спецификации. Все метапеременные, содержащиеся в правилах, должны быть аннотированы уровнями выражений, для проверки спецификации.

Затем описание проходит проверку на корректность (определение языка спецификации и проверки описаны в Разделе~\ref{lang_spec}). Эта проверка должна исключать как просто некорректно записанные языки, так и языки для которых генерация кода будет проблематичной или невозможной. Поэтому важной частью этой подзадачи является огрничения множества языков, которые возможно специфицировать в нашем языке.

Стоит отметить, что спецификация позволяет задавать нестабильные теории (см. Раздел~\ref{lang_spec} для более подробного описания). Это ограничение полезно для определенных теоретических применений теории типов, которые мы не будем обсуждать в данной работе, так как они выходят за ее рамки. Одним из применений нестабильности является~\cite{ncat:inf}.

% Например, если мы хотим, чтобы конструкцию if-then-else можно было применять только, если все свободные переменные внутри неё имеют тип Bool или являются функциями из Bool в Bool, мы можем проаннотировать соответствующее правило вывода списком типов $[Bool, Bool\rightarrow Bool]$.

\subsection*{Реализация}\label{impl_intro}

После проверок спецификации (описанных в Разделе~\ref{constraints}) строится структура хранящая информацию о правилах вывода, редукциях и конструкциях языка. С её помощью происходит кодогенерация представления термов языка и функций проверки типов и вычисления.

В дальнейшем мы понимаем вычисление как переписывание термов согласно редукциям языка, пока не получим терм к которому ни одна редукция неприменима --- этот процесс называется приведением терма в \textit{нормальную форму}.

Нормализация генерируется по правилам редукции, описанным в спецификации, функция проверки типов --- по правилам вывода. Неявно подразумевается, что в языке есть отношение эквивалентности на термах, которое порождается отношением редукции. Это выражается в том, что сравнение термов (которое сравнивает их с точностью до этого отношения эквивалентности) сначала нормализует термы, а потом сравнивает их нормальные формы.

Так как типы зависимого языка могут включать в себя произвольные термы, проверка типов является задачей тесно связанной с вычислением языка. Например, если наша функция принимает только списки длинны числа фибоначчи, а нам передана конкатенация списков длины 2 и 3 то, чтобы понять является ли это число числом фибоначчи, нам нужно его вычислить $2 + 3 => 5$, также вычислить первые несколько чисел фибоначчи, положим числа фибоначчи определены как список $[1,1,2,3,5,8,...]$, затем вычислить предикат принадлежности $5 \in fibs$ и только тогда мы можем вызвать функцию сравнения термов. Также стоить заметить что термы могут иметь достаточно сложную нормальную форму и нам может прийтись сравнивать АСД этих термов.

Поэтому написание функции проверки типов языка становится достаточно ёмкой задачей --- мы должны попутно реализовывать функцию нормализации. Однако общий алгоритм проверки типов не сильно отличается от языка к языку --- всегда нужно рекурсивно проверять АСД на удовлетворение правилам вывода, таким образом его можно генерировать по спецификации, при наличии достаточного количества ограничений на последнюю (подробнее в Разделе~\ref{typecheck}).


Как упоминалось выше, правильно выбранное представление может значительно упростить генерацию кода. Также существуют варианты представления, дающие больше гарантий на корректность составления термов языка, благодаря более строгой типизации. Рассмотрены несколько вариантов представления (см. Раздел~\ref{term_repr} для подробного обсуждения этих вариантов):
\begin{enumerate}
\item Обычное именованное (переменные представляются в виде строк)
\item Обычные индексы де Брейна\cite{de_brujin} (переменные явяются целыми числами, указывающими на место их связывания)
\item Индексы де Брейна с использованием полиморфной рекурсии\cite{poly_rec}
\end{enumerate}

У первых двух способов представления есть недостатки. В первом необходимо вводить $\alpha$-эквивалентность на термах --- \textit{$\alpha$-эквивалентными} называются термы, которые отличаются только в именовании связанных переменных. Во втором варианте возникают сложности с работой под связываниями переменных --- а именно, так как процесс проверки типов рекурсивен, мы должны гарантировать корректность подтермов при рекурсином вызове, однако .

Также в каждом из этих случаев легко допустить ошибку при работе с термами. Третий вариант является модификацией второго, в которой совершать ошибки при работе с индексами сложнее из-за проверок на уровне типов, таким образом код пользователя получается имеет больше гарантий корректности.

Также третий подход позволяет с большей легкостью генерировать операции над термами: равенство проверяется непосредственно, подстановки и абстракция тоже не составляют больших усилий.





%%
